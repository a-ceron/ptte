{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 2\n",
    "Construye un modelo básico de preguntas y respuestas.\n",
    "\n",
    "## Fuente de datos.\n",
    "\n",
    "\n",
    "## Resumen de la implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aceron/opt/miniconda3/envs/courses/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-06-18 19:58:32.047164: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 910kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 37.5kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 921kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 440M/440M [03:19<00:00, 2.21MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/aceron/opt/miniconda3/envs/courses/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "1 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong@gmail.com/Mi unidad/Personal/CV/Junio 2023/ptte/reto_2/Solucion.ipynb Celda 2\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Entrenamiento del modelo\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         input_ids \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/courses/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/courses/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/courses/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/courses/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong@gmail.com/Mi unidad/Personal/CV/Junio 2023/ptte/reto_2/Solucion.ipynb Celda 2\u001b[0m in \u001b[0;36mQADataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreguntas[idx],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrespuestas[idx],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m: encoding[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: encoding[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze(),\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstart_positions\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mtensor([encoding[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49msqueeze()\u001b[39m.\u001b[39;49mtolist()\u001b[39m.\u001b[39;49mindex(\u001b[39m1\u001b[39;49m)]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mend_positions\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39mtensor([encoding[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtolist()\u001b[39m.\u001b[39mindex(\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrespuestas[idx]\u001b[39m.\u001b[39msplit()) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aceron/Library/CloudStorage/GoogleDrive-arielcerong%40gmail.com/Mi%20unidad/Personal/CV/Junio%202023/ptte/reto_2/Solucion.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: 1 is not in list"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForQuestionAnswering, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "# Definir la clase del conjunto de datos de preguntas y respuestas\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, preguntas, respuestas, tokenizer):\n",
    "        self.preguntas = preguntas\n",
    "        self.respuestas = respuestas\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preguntas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            self.preguntas[idx],\n",
    "            self.respuestas[idx],\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'start_positions': torch.tensor([encoding['input_ids'].squeeze().tolist().index(1)]),\n",
    "            'end_positions': torch.tensor([encoding['input_ids'].squeeze().tolist().index(1) + len(self.respuestas[idx].split()) - 1])\n",
    "        }\n",
    "\n",
    "# Datos de ejemplo\n",
    "preguntas = [\n",
    "    \"¿Qué es la inteligencia artificial?\",\n",
    "    \"¿En qué se utiliza la inteligencia artificial?\",\n",
    "    \"¿Cuáles son algunas aplicaciones de la inteligencia artificial?\"\n",
    "]\n",
    "respuestas = [\n",
    "    \"La inteligencia artificial (IA) es un campo de estudio multidisciplinario que busca desarrollar algoritmos y sistemas capaces de imitar el razonamiento y la toma de decisiones humanas.\",\n",
    "    \"La inteligencia artificial se utiliza en una amplia variedad de aplicaciones, como reconocimiento de voz, chatbots, conducción autónoma y mucho más.\",\n",
    "    \"Algunas aplicaciones de la inteligencia artificial incluyen reconocimiento facial, asistentes virtuales, sistemas de recomendación, entre otros.\"\n",
    "]\n",
    "\n",
    "# Inicializar el tokenizador y el modelo\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "modelo = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Crear el conjunto de datos y el DataLoader\n",
    "dataset = QADataset(preguntas, respuestas, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Configurar el optimizador\n",
    "optimizador = AdamW(modelo.parameters(), lr=2e-5)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(3):\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        start_positions = batch['start_positions']\n",
    "        end_positions = batch['end_positions']\n",
    "\n",
    "        modelo.zero_grad()\n",
    "        outputs = modelo(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizador.step()\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "modelo.save_pretrained('ruta/al/modelo/entrenado')\n",
    "tokenizer.save_pretrained('ruta/al/tokenizador/entrenado')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "courses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
